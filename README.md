# LayoutPointer

official code for the paper LayoutPointer: A Spatial-Context Adaptive Pointer Network for Visual Information Extraction

# Datasets

MLFUD dataset in XFUND format (reconstructed from [XFUND](https://github.com/doc-analysis/XFUND) and [FUNSD](https://guillaumejaume.github.io/FUNSD/))

ZIP: [Google Drive](https://drive.google.com/drive/folders/1IXe0QOEUh_XgbdQspBPK5_hvExR7rr8G?usp=drive_link), visualize it via [datautils/xfund_visual_re.py](datautils/xfund_visual_re.py)

# Models

LayoutPointer: go to layoutlmft/models/gplayoutlmv3

# Training 

The training code is largely based on the public official [layoutlmv3](https://github.com/microsoft/unilm) repo with some project-specific modifications.
I’ll consider releasing it once it’s better organized.

# Thanks

[https://github.com/microsoft/unilm/tree/master/layoutlmv3](https://github.com/microsoft/unilm)

[https://github.com/bojone/GPLinker](https://github.com/bojone/GPLinker)

[https://github.com/ZhuiyiTechnology/roformer](https://github.com/ZhuiyiTechnology/roformer)

[https://kexue.fm/archives/8397](https://kexue.fm/archives/8397)

# Contact

siyuanh963@163.com
